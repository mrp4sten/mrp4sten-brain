[[1. Kubernetes]]

Resource management in Kubernetes involves managing CPU, memory, and storage resources to ensure efficient and effective use of resources. Kubernetes provides several features and tools, including resource quotas, limits, node affinity and anti-affinity, horizontal and vertical pod autoscaling, and cluster autoscaling to manage resources effectively. These features help ensure that resources are allocated fairly, resource contention is avoided, and pods have access to the resources they need. By using these features, Kubernetes can efficiently manage resources, leading to better performance, improved reliability, and reduced costs.
## Setting resource requests and limitations
Resource requests and limits in Kubernetes specify the minimum and maximum amount of CPU and memory a container requires to run. Resource requests are used for scheduling containers on nodes with sufficient resources, while limits enforce resource quotas and prevent containers from consuming too much. These settings can be configured at the pod or container level using the resources field in YAML. Itâ€™s important to set resource requests and limits correctly to ensure optimal resource utilization in your Kubernetes cluster.
> [Requests and limits](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits)
## Assigning quotas to namespaces
Assigning quotas to namespaces is a way to limit resource usage for specific groups of resources in Kubernetes. Quotas can be set for CPU, memory, and other resources, as well as for the number of objects in a namespace. This can help ensure fair resource distribution across different teams or projects within a cluster. Quotas can be applied to individual namespaces or across the entire cluster. Kubernetes allows for both hard quotas, which enforce strict resource limits, and soft quotas, which allow for overages up to a certain point. Quotas can be managed using the Kubernetes API or through YAML configuration files.
> [Quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/)
## Monitoring and optimizing resource usage
Monitoring and optimizing resource usage in Kubernetes (k8s) is crucial for ensuring efficient and effective use of resources. To monitor resource usage, k8s provides a Metrics Server, and Prometheus can be integrated with k8s. The Container Runtime Interface (CRI) can also be used to monitor container-level resource usage data. To optimize resource usage, setting appropriate requests and limits, using Horizontal Pod Autoscaling (HPA), implementing pod affinity and anti-affinity rules, and controlling node selection can all help reduce resource contention and improve resource utilization. By monitoring and optimizing resource usage, k8s can ensure that applications run efficiently and resources are used effectively.
> [Tools for monitoring resources](https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-usage-monitoring/)

